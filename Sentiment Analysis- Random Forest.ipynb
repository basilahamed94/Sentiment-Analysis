{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import bz2\n",
    "import gc\n",
    "import chardet\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = bz2.BZ2File('train.ft.txt.bz2')\n",
    "test_file = bz2.BZ2File('test.ft.txt.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_req_data(req_lines):\n",
    "    return int(448.374641923*req_lines)\n",
    "def get_req_data_score(req_lines):\n",
    "    return int(452.488687783*req_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99255 24914\n"
     ]
    }
   ],
   "source": [
    "train_file_lines = train_file.readlines(get_req_data(100000))\n",
    "test_file_lines = test_file.readlines(get_req_data_score(25000))\n",
    "del train_file, test_file\n",
    "train_file_lines = [x.decode('utf-8') for x in train_file_lines]\n",
    "test_file_lines = [x.decode('utf-8') for x in test_file_lines]\n",
    "print(len(train_file_lines) ,len(test_file_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99255 24914\n"
     ]
    }
   ],
   "source": [
    "#Seprating scores from reviews\n",
    "length_of_train = len(train_file_lines)\n",
    "length_of_test = len(test_file_lines)\n",
    "print(length_of_train , length_of_test)\n",
    "train_file_lines_score = []\n",
    "test_file_lines_score = []\n",
    "for i in range(0,length_of_train):\n",
    "    temp = train_file_lines[i][9]\n",
    "    train_file_lines_score.append(temp)\n",
    "\n",
    "for i in range(0,length_of_test):\n",
    "    temp = test_file_lines[i][9]\n",
    "    test_file_lines_score.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 1) (24914, 1) (75000, 1) (24914, 1)\n"
     ]
    }
   ],
   "source": [
    "#Converting python list to dataframe\n",
    "df_train_reviews = pd.DataFrame({'reviews': train_file_lines} )\n",
    "df_test_reviews = pd.DataFrame({'reviews': test_file_lines} )\n",
    "df_train_score = pd.DataFrame({'score': train_file_lines_score} )\n",
    "df_test_score = pd.DataFrame({'score': test_file_lines_score} )\n",
    "\n",
    "#taking less reviews due to limited computational power\n",
    "df_train_reviews = df_train_reviews[:75000]\n",
    "df_test_reviews = df_test_reviews[:25000]\n",
    "df_train_score = df_train_score[:75000]\n",
    "df_test_score = df_test_score[:25000]\n",
    "\n",
    "print(df_train_reviews.shape,df_test_reviews.shape,df_train_score.shape,df_test_score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shino\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shino\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'stuning even non gamer sound track beautiful paint senery mind well would recomend even people hate vid game music played game chrono cross game ever played best music back away crude keyboarding take fresher step grate guitar soulful orchestra would impress anyone care listen'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#Pre-processing reviews data of traning set\n",
    "corpus_train = []\n",
    "for i in range(0, len(df_train_reviews)):\n",
    "    review = re.sub(\"<.*?>\", \"\", df_train_reviews['reviews'][i])\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    del review[0]\n",
    "    #ps = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    #review = [ps.stem(words) for words in review if not words in set(stopwords.words('english'))]\n",
    "    review = [lemmatizer.lemmatize(words) for words in review if not words in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus_train.append(review)\n",
    "    \n",
    "#Pre-processing reviews data of testing set\n",
    "corpus_test = []\n",
    "for i in range(0, len(df_test_reviews)):\n",
    "    review = re.sub(\"<.*?>\", \"\", df_test_reviews['reviews'][i])\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    del review[0]\n",
    "    #ps = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    #review = [ps.stem(words) for words in review if not words in set(stopwords.words('english'))]\n",
    "    review = [lemmatizer.lemmatize(words) for words in review if not words in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus_test.append(review)\n",
    "\n",
    "corpus_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 5000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bag of words(sparc matrix)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#cv = TfidfVectorizer(ngram_range=(1,2))\n",
    "cv = TfidfVectorizer(max_features=5000)\n",
    "X_train = cv.fit_transform(corpus_train).toarray()\n",
    "X_test = cv.transform(corpus_test).toarray()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8467126916593081"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 100, criterion = 'gini', random_state = 0 , max_depth=100)\n",
    "classifier.fit(X_train, df_train_score)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(df_test_score, y_pred)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(df_test_score , y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
